{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Colab compatible version\n",
        "The following setup is suitable for Google Colab with T4 GPU.\n",
        "\n",
        "To enable T4 GPU: Connect configuration menu $\\rightarrow$ Change runtime type $\\rightarrow$ Hardware accelerator: T4 GPU"
      ],
      "metadata": {
        "id": "Ho7QzWvk8IcB"
      },
      "id": "Ho7QzWvk8IcB"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gmum/ml2024-25.git"
      ],
      "metadata": {
        "id": "RWInpnEv7_d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caa5823-1d4f-4c3e-d3ae-559a5ff4e653"
      },
      "id": "RWInpnEv7_d9",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml2024-25'...\n",
            "remote: Enumerating objects: 151, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 151 (delta 24), reused 20 (delta 17), pack-reused 116 (from 1)\u001b[K\n",
            "Receiving objects: 100% (151/151), 37.37 MiB | 11.00 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n",
            "Updating files: 100% (82/82), done.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/ml2024-25')  # This ensures import lab.checker later"
      ],
      "metadata": {
        "id": "zAjf4bUx42z8"
      },
      "id": "zAjf4bUx42z8",
      "outputs": [],
      "execution_count": 2
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e670bf640f110540",
        "outputId": "b03eba28-2d1c-4bbc-8774-9f1fabd84c1d"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121"
      ],
      "id": "e670bf640f110540",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (799.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.1/799.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp310-cp310-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.24.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.24.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.24.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
            "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu121\n",
            "    Uninstalling torchaudio-2.5.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu121\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0+cu121 torchaudio-2.4.0+cu121 torchvision-0.19.0+cu121 triton-3.0.0\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html"
      ],
      "metadata": {
        "id": "aQPY-MIt8VaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29020770-b133-449a-96f8-c6bcb6e76d79"
      },
      "id": "aQPY-MIt8VaW",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/torch-2.4/cu121/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/torch-2.4/cu121/dgl-2.4.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (355.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.2/355.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from dgl) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgl) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from dgl) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: torch<=2.4.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.4.0+cu121)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->dgl) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2024.12.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.4.0->dgl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<=2.4.0->dgl) (12.6.85)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgl) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->dgl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.4.0->dgl) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<=2.4.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.4.0+cu121\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgllife"
      ],
      "metadata": {
        "id": "Yoyd-1nt8XVQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fe9177-4588-4c3c-c2b9-5c4442911afd"
      },
      "id": "Yoyd-1nt8XVQ",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl.metadata (667 bytes)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgllife) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgllife) (3.4.2)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from dgllife) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->dgllife) (2024.12.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (3.1.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->dgllife) (2024.2)\n",
            "Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/226.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html  # Optional dependencies"
      ],
      "metadata": {
        "id": "kx1Y0mtj8ZRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd2169c-1ae4-4fe1-ad47-388529763f44"
      },
      "id": "kx1Y0mtj8ZRA",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.11)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/pyg_lib-0.4.0%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_sparse-0.6.18%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_cluster-1.6.3%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_spline_conv-1.2.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (986 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.2/986.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.26.4)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.4.0+pt24cu121 torch_cluster-1.6.3+pt24cu121 torch_scatter-2.1.2+pt24cu121 torch_sparse-0.6.18+pt24cu121 torch_spline_conv-1.2.2+pt24cu121\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit==2022.3.5"
      ],
      "metadata": {
        "id": "mrO7asE88-My",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3083ac-3508-4a36-ed07-47c28207aeca"
      },
      "id": "mrO7asE88-My",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit==2022.3.5\n",
            "  Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit==2022.3.5) (11.1.0)\n",
            "Downloading rdkit-2022.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/37.0 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2022.3.5\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "mjrdsp9W8fTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e094e32-11fc-4a1a-cb68-38574a9c1572"
      },
      "id": "mjrdsp9W8fTr",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "id": "9bec6577a3d2a155",
      "metadata": {
        "collapsed": false,
        "id": "9bec6577a3d2a155"
      },
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "## Part I: Message Passing Neural Networks (MPNNs)\n",
        "We are going to implement few MPNNs for molecular property prediciton. It's recommended that you're familiar with the recent lectures on GNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a10f517285d85363",
      "metadata": {
        "collapsed": false,
        "id": "a10f517285d85363"
      },
      "source": [
        "# Packages for GNNs\n",
        "There two very popular packages for GNNs that uses pytorch as a backend:\n",
        "1. [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html).\n",
        "2. [Deep Graph Library](https://www.dgl.ai/pages/start.html) (along with [dgl-lifesci](https://lifesci.dgl.ai/install/index.html).\n",
        "The former is more stable, the latter has a convenient extension [dgl-lifesci](https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html) for molecular data and is generally much more user-friendly. For convenience, we are going to use all three packages, so install appropriate versions of them, please (I recommend installing with pip). If you have issues with installing rdkit (required by dgl-lifesci), you can install rdkit using pip (pip install rdkit)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46af56ed",
      "metadata": {
        "id": "46af56ed"
      },
      "source": [
        "## Installation commands\n",
        "The following commands should work for the `ml` conda env from the `01_zasady_wstep.ipynb`.\n",
        "\n",
        "```\n",
        "conda install -c dglteam/label/cu117 dgl\n",
        "conda install -c conda-forge dgllife\n",
        "conda install pyg -c pyg\n",
        "\n",
        "conda install libboost=1.73.0 boost=1.73.0 boost-cpp=1.73.0\n",
        "pip install rdkit==2022.3.5\n",
        "\n",
        "conda install -c conda-forge torchmetrics\n",
        "conda install -c conda-forge wandb\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61eff200e2fa43b4",
      "metadata": {
        "collapsed": false,
        "id": "61eff200e2fa43b4"
      },
      "source": [
        "# Molecular graphs\n",
        "(Copied from [mldd23 repository](https://github.com/gmum/mldd23/blob/main/labs/L3-graph-neural-networks/laboratory.ipynb))\n",
        "In mathematics, a graph is an object that consists of a set of vertices (nodes) connected with edges, i.e. $\\mathcal{G} = (V, E)$, where $V = \\{ v_i: i \\in \\{1, 2, \\dots, N \\} \\}$ and $E \\subseteq \\{ (v_i, v_j):\\, v_i,v_j \\in V \\}$.\n",
        "\n",
        "Molecular graphs are a special class of graphs, where besides nodes (denoting atoms) and edges (denoting chemical bonds), we have an additional information about atom types and sometimes also bond types. We can assume that we have an additional set of node/atom features encoded as a matrix $X$, where $X_{ij}$ is the $j$-th feature of the $i$-th atom. As atomic features, we can have one-hot encoded atom symbols (a vector containing zeros on all positions besides the position that corresponds to the atom symbol), the number of implicit hydrogens bonded with this atom, or the number of heavy neighbors (atoms other than hydrogens bonded to the given atom).\n",
        "\n",
        "Egdes/bonds can be encoded in two different ways. One method is to use an adjacency matrix $A$, where $A_{ij}=1$ if nodes/atoms $v_i$ nad $v_j$ are connected ($A_{ij}=0$ otherwise). In the case of sparse matrices, a more useful encoding is a list of pairs of connected atoms (a list of index pairs). This latter enocding is used by the PyTorch-Geometric library.\n",
        "\n",
        "In practice, a molecular graph can be described by two matrices: $X \\in \\mathbb{R}^{N \\times F}$ and $E \\in \\{0, 1,\\dots,N-1\\}^{2 \\times N}$, where $N$ is the number of atoms, and $F$ is the number of atomic features.\n",
        "<img src=\"resources/mol_graph.png\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7533978cf98913d",
      "metadata": {
        "collapsed": false,
        "id": "7533978cf98913d"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7eeba76a4a89736",
      "metadata": {
        "collapsed": false,
        "id": "f7eeba76a4a89736"
      },
      "source": [
        "We are going to use FreeSolv dataset that contains 642 hydration free energy values for small molecules. The goal is to predict the [hydration free energy](https://en.wikipedia.org/wiki/Hydration_energy) of a given molecule. It's a very commonly used dataset for benchmarking molecular property prediction models. It's small, so we can minimize our co2 footprint and time spent on training.\n",
        "\n",
        "Molecules in most chemical datasets are represented with SMILES. SMILES is a linearization of the molecular graph, it's pretty convenient and can even be used as an input to text-based models. Fortunately, dgllife provides a fancy FreeSolv dataset wrapper that will 1) transform the SMILES into a molecular graph, and 2) encode the nodes and edges with some sensible chemical features (like atom types, bond type etc.) with node and edge features, so we don't really need to care about it."
      ]
    },
    {
      "cell_type": "code",
      "id": "e6b97de5d9371cf2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "b284230058d74e42a500416500d08ebb",
            "9fae3655b19d405f83b190de344b92d3",
            "a0439ca35e774705a20af1ecfe258c3b",
            "07f88eff19324c67aa25f67c7082a94b",
            "5e00f9a70be44a08933b3988a180e302",
            "1491a96d59804c10b66f314abf355061",
            "f73966e6f43b45dfbe922ea2079e4e88",
            "041912511f044599b363309886a1d237",
            "cd1ec0c3949b46ebae2dab78530b9dee",
            "9502bcf5090d482da8417c0d0b574c7b",
            "afe6245eeee94220a59e13396ad1bac8"
          ]
        },
        "id": "e6b97de5d9371cf2",
        "outputId": "554ab562-4787-45ad-cec9-875388d1a02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Downloading /root/.dgl/FreeSolv.zip from https://data.dgl.ai/dataset/FreeSolv.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/root/.dgl/FreeSolv.zip:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b284230058d74e42a500416500d08ebb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting file to /root/.dgl/FreeSolv\n",
            "Processing dgl graphs from scratch...\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import (CanonicalAtomFeaturizer,\n",
        "                           CanonicalBondFeaturizer,\n",
        "                           SMILESToBigraph)\n",
        "from dgllife.data import FreeSolv\n",
        "import torch\n",
        "import dgl\n",
        "\n",
        "node_featurizer = CanonicalAtomFeaturizer()\n",
        "edge_featurizer = CanonicalBondFeaturizer(self_loop=True)\n",
        "dataset = FreeSolv(\n",
        "    smiles_to_graph=SMILESToBigraph(\n",
        "        node_featurizer=node_featurizer,\n",
        "        edge_featurizer=edge_featurizer,\n",
        "        add_self_loop=True, # well... some of the molecules in the dataset contain no edges, so adding the self-loop (edge from node to itself) makes the future MPNN implementations simpler.\n",
        "    ),\n",
        ")"
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "id": "9bf700b3346f6a31",
      "metadata": {
        "collapsed": false,
        "id": "9bf700b3346f6a31"
      },
      "source": [
        "## Playground"
      ]
    },
    {
      "cell_type": "code",
      "id": "fd08f424238c9580",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd08f424238c9580",
        "outputId": "d93c6f11-e3a9-4a79-ff9b-4f001330186b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('CN(C)C(=O)c1ccc(cc1)OC',\n",
              " Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " tensor([-11.0100]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "smiles, graph, label = dataset[0]\n",
        "smiles, graph, label"
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "id": "b297de83ea20e626",
      "metadata": {
        "collapsed": false,
        "id": "b297de83ea20e626"
      },
      "source": [
        "We see that the dataset item consist of a SMILES string, a graph, and a label. The graph is a [DGLGraph](https://docs.dgl.ai/en/0.8.x/api/python/dgl.DGLGraph.html) object that contains node and edge features. We can access them with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "id": "f6cd6aafddd20202",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6cd6aafddd20202",
        "outputId": "e50bd6ea-9cfc-4250-86c7-76d8e7c45af1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 74])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "graph.ndata['h'].shape  # node features"
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "id": "972195282cdfb48f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972195282cdfb48f",
        "outputId": "55ba0843-b11c-45d8-93e9-b28af2d4e600"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([39, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "graph.edata['e'].shape  # edge features"
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "id": "bf1af8de0703b2d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf1af8de0703b2d3",
        "outputId": "5df9f2b0-7278-4a1b-b12e-7cc40a2ecfe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12,  0],\n",
              "        [ 0, 12],\n",
              "        [ 0,  2],\n",
              "        [ 2,  0],\n",
              "        [ 0,  4],\n",
              "        [ 4,  0],\n",
              "        [ 4,  7],\n",
              "        [ 7,  4],\n",
              "        [ 4,  9],\n",
              "        [ 9,  4],\n",
              "        [ 9,  6],\n",
              "        [ 6,  9],\n",
              "        [ 6, 10],\n",
              "        [10,  6],\n",
              "        [10, 11],\n",
              "        [11, 10],\n",
              "        [11,  3],\n",
              "        [ 3, 11],\n",
              "        [ 3,  8],\n",
              "        [ 8,  3],\n",
              "        [11,  5],\n",
              "        [ 5, 11],\n",
              "        [ 5,  1],\n",
              "        [ 1,  5],\n",
              "        [ 8,  9],\n",
              "        [ 9,  8],\n",
              "        [ 0,  0],\n",
              "        [ 1,  1],\n",
              "        [ 2,  2],\n",
              "        [ 3,  3],\n",
              "        [ 4,  4],\n",
              "        [ 5,  5],\n",
              "        [ 6,  6],\n",
              "        [ 7,  7],\n",
              "        [ 8,  8],\n",
              "        [ 9,  9],\n",
              "        [10, 10],\n",
              "        [11, 11],\n",
              "        [12, 12]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "start_nodes, end_nodes = graph.edges()  # edges. Note that edges are directed, so we have two edges for each bond. Moreover, we have self-loops, to easily handle molecules with only one atom.\n",
        "edges = torch.stack([start_nodes, end_nodes], dim=1)\n",
        "edges"
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "id": "611ba9d29599927d",
      "metadata": {
        "collapsed": false,
        "id": "611ba9d29599927d"
      },
      "source": [
        "Importantly, if we want to create a batch of graphs, we can simply treat the graphs as... a single graph with many disconnected components. The reason is that MPNN cannot pass the message between disconnected compontents, so the graphs in a batch won't influence each other. To make a batch from two graphs, we can simply run:"
      ]
    },
    {
      "cell_type": "code",
      "id": "1063ec4d70a6c648",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1063ec4d70a6c648",
        "outputId": "6b7fc372-cc5c-401f-d71c-1bcc583c4896"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Graph(num_nodes=13, num_edges=39,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=5, num_edges=13,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}),\n",
              " Graph(num_nodes=18, num_edges=52,\n",
              "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
              "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)}))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "_, graph_1, _ = dataset[0]\n",
        "_, graph_2, _ = dataset[1]\n",
        "collated_graph = dgl.batch([graph_1, graph_2])\n",
        "graph_1, graph_2, collated_graph"
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "id": "cd9357b97e4c3b1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9357b97e4c3b1b",
        "outputId": "30e00532-b02d-4e8d-9030-082e2cead971"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([13,  5], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "collated_graph.batch_num_nodes()"
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "id": "b37a35a6ae91e55d",
      "metadata": {
        "collapsed": false,
        "id": "b37a35a6ae91e55d"
      },
      "source": [
        "In the collated_graph, the ids corresponding to the nodes of graph_2 are shifted by the size of graph_1:"
      ]
    },
    {
      "cell_type": "code",
      "id": "7598293d45c78c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7598293d45c78c0",
        "outputId": "4ad4e99e-b99e-43a1-f4b8-2e1f49ee3e4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=torch.int32),\n",
              " tensor([0, 1, 2, 3, 4], dtype=torch.int32),\n",
              " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
              "        dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "graph_1.nodes(), graph_2.nodes(), collated_graph.nodes()"
      ],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "id": "e67b6515649fa77d",
      "metadata": {
        "collapsed": false,
        "id": "e67b6515649fa77d"
      },
      "source": [
        "## Split\n",
        "We are going to make our split slightly harder by using [scaffold](https://hub.knime.com/infocom/extensions/jp.co.infocom.cheminfo.jchem.feature/latest/jp.co.infocom.cheminfo.jchem.bemismurckoclustering.BemisMurckoClusteringNodeFactory) (scaffold is the largest cycle in a molecule) splitting that puts molecules with similar scaffolds to the same split."
      ]
    },
    {
      "cell_type": "code",
      "id": "901db3d9cdc5a748",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "901db3d9cdc5a748",
        "outputId": "add21019-7cf8-467d-cd6a-76fd713d8792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start initializing RDKit molecule instances...\n",
            "Start computing Bemis-Murcko scaffolds.\n"
          ]
        }
      ],
      "source": [
        "from dgllife.utils import ScaffoldSplitter\n",
        "\n",
        "splitter = ScaffoldSplitter()\n",
        "train, valid, test = splitter.train_val_test_split(dataset)"
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "id": "b6a601dc47074ca6",
      "metadata": {
        "collapsed": false,
        "id": "b6a601dc47074ca6"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be6593567ea5467",
      "metadata": {
        "collapsed": false,
        "id": "be6593567ea5467"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "id": "e75cf00937a3c413",
      "metadata": {
        "id": "e75cf00937a3c413"
      },
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from tqdm.autonotebook import tqdm\n",
        "from dgl.dataloading import GraphDataLoader\n",
        "from torchmetrics import Metric\n",
        "from dgl.data import Subset\n",
        "from torch import nn\n",
        "from typing import Type\n",
        "from typing import Dict, Any\n",
        "from pathlib import Path\n",
        "from abc import ABC, abstractmethod\n",
        "from checker import expected_mean_readout, expected_gin_layer_output, expected_sage_layer_output, \\\n",
        "    expected_attention_readout, expected_gine_layer_output, expected_sum_readout, expected_simple_mpnn_output\n",
        "\n",
        "\n",
        "class LoggerBase(ABC):\n",
        "    def __init__(self, logdir: str | Path):\n",
        "        self.logdir = Path(logdir)\n",
        "        self.logdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    @abstractmethod\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        ...\n",
        "\n",
        "    @abstractmethod\n",
        "    def close(self):\n",
        "        ...\n",
        "\n",
        "\n",
        "class DummyLogger(LoggerBase):  # If you don't want to use any logger, you can use this one\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "    def restart(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class MetricList:\n",
        "    def __init__(self, metrics: Dict[str, Metric]):\n",
        "        self.metrics = copy.deepcopy(metrics)\n",
        "\n",
        "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
        "        for name, metric in self.metrics.items():\n",
        "            metric.update(preds.detach().cpu(), targets.cpu())\n",
        "\n",
        "    def compute(self) -> Dict[str, float]:\n",
        "        metrics = {}\n",
        "        for name, metric_fn in self.metrics.items():\n",
        "            metrics[name] = metric_fn.compute().item()\n",
        "            metric_fn.reset()\n",
        "        return metrics\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(\n",
        "            self,\n",
        "            *,\n",
        "            run_dir: str | Path,\n",
        "            train_dataset: Subset,\n",
        "            valid_dataset: Subset,\n",
        "            train_metrics: Dict[str, Metric],\n",
        "            valid_metrics: Dict[str, Metric],\n",
        "            model: nn.Module,\n",
        "            logger: LoggerBase,\n",
        "            optimizer_kwargs: Dict[str, Any],\n",
        "            optimizer_cls: Type[torch.optim.Optimizer] = torch.optim.Adam,\n",
        "            n_epochs: int,\n",
        "            train_batch_size: int = 32,\n",
        "            valid_batch_size: int = 16,\n",
        "            device: str = \"cuda\",\n",
        "            valid_every_n_epochs: int = 1,\n",
        "            loss_fn=nn.MSELoss()\n",
        "    ):\n",
        "        self.run_dir = Path(run_dir)\n",
        "        self.train_loader = GraphDataLoader(\n",
        "            dataset=train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.valid_loader = GraphDataLoader(\n",
        "            dataset=valid_dataset,\n",
        "            batch_size=valid_batch_size,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        self.train_metrics = MetricList(train_metrics)\n",
        "        self.valid_metrics = MetricList(valid_metrics)\n",
        "        self.logger = logger\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer_cls(model.parameters(), **optimizer_kwargs)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "        self.valid_every_n_epochs = valid_every_n_epochs\n",
        "        self.loss_fn = loss_fn\n",
        "        self.model.to(device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, dataloader: GraphDataLoader, prefix: str) -> Dict[str, float]:\n",
        "        previous_mode = self.model.training\n",
        "        self.model.eval()\n",
        "        losses = []\n",
        "        for _, graphs, labels in dataloader:\n",
        "            graphs = graphs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self.model(graphs)\n",
        "            loss = self.loss_fn(preds, labels)\n",
        "            losses.append(loss.item())\n",
        "            self.valid_metrics.update(preds, labels)\n",
        "        self.model.train(mode=previous_mode)\n",
        "        metrics = {\"loss\": np.mean(losses)} | self.valid_metrics.compute()\n",
        "        self.logger.log_metrics(metrics=metrics, prefix=prefix)\n",
        "        return metrics\n",
        "\n",
        "    def train(self) -> Dict[str, float]:\n",
        "        self.model.train()\n",
        "        valid_metrics = {}\n",
        "        for epoch in tqdm(range(self.n_epochs), total=self.n_epochs):\n",
        "            for _, graphs, labels in self.train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                graphs = graphs.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                preds = self.model(graphs)\n",
        "                loss = self.loss_fn(preds, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                self.train_metrics.update(preds, labels)\n",
        "                train_metrics = {\"loss\": loss.item()} | self.train_metrics.compute()\n",
        "                self.logger.log_metrics(metrics=train_metrics, prefix=\"train\")\n",
        "\n",
        "                if epoch % self.valid_every_n_epochs == 0 or epoch == self.n_epochs - 1:\n",
        "                    valid_metrics = self.validate(self.valid_loader, prefix=\"valid\")\n",
        "\n",
        "        return valid_metrics\n",
        "\n",
        "    def test(self, dataset: Subset) -> Dict[str, float]:\n",
        "        dataloader = GraphDataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=16,\n",
        "            shuffle=False,\n",
        "        )\n",
        "        return self.validate(dataloader, prefix=\"test\")\n",
        "\n",
        "    def close(self):  # close the logger, not really required for wandb\n",
        "        self.logger.close()"
      ],
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "id": "7d54c9a1e68cd221",
      "metadata": {
        "collapsed": false,
        "id": "7d54c9a1e68cd221"
      },
      "source": [
        "# Graph Neural Networks (GNNs)\n",
        "The high-level Graph Neural Network architecture we are going to use looks roughly like this:\n",
        "\n",
        "<img src=\"resources/gnn.png\" width=\"1200\" />\n",
        "\n",
        "- The Featurizer takes a molecule and transforms it to a graph with node and edge features (it happens at the level of dataset, so we don't really need to worry about that).\n",
        "- In our case, we will linearly embed the node and edge features to the hidden size before applying first MPNN layer which is not captured in the diagram.\n",
        "- The MPNN layer takes node (and possibly edge embeddings) and the graph structure and returns updated node embeddings. It happens in a loop.\n",
        "- Then the node embeddings are aggregated by the Readout layer to obtain a graph embeddings.\n",
        "- Finally, the graph embeddings are passed to the MLP to obtain the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "id": "e6e7df76cc963d8b",
      "metadata": {
        "id": "e6e7df76cc963d8b"
      },
      "source": [
        "class MPNNLayerBase(ABC, nn.Module):\n",
        "    def _init(self, hidden_size: int):\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            hidden_size: the size of node (and edges) embeddings\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class ReadoutBase(nn.Module):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        ...\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 node_features_size: int,\n",
        "                 edge_features_size: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size: int,\n",
        "                 mpnn_layer_cls: Type[MPNNLayerBase],\n",
        "                 mpnn_layer_kwargs: Dict[str, Any],\n",
        "                 mpnn_n_layers: int,\n",
        "                 readout_cls: Type[ReadoutBase]):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_features_size: the size of node features\n",
        "            edge_features_size: the size of edge features\n",
        "            hidden_size: the size of node (and edge) embeddings\n",
        "            output_size: the size of the final prediction\n",
        "            mpnn_layer_cls: the class of MPNN layer\n",
        "            mpnn_layer_kwargs: the kwargs for the MPNN layer\n",
        "            mpnn_n_layers: the number of MPNN layers\n",
        "            readout_cls: the class of Readout layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.linear_node = nn.Linear(node_features_size, hidden_size)\n",
        "        self.linear_edge = nn.Linear(edge_features_size, hidden_size)\n",
        "        self.mpnn_layers = nn.ModuleList([\n",
        "            mpnn_layer_cls(hidden_size=hidden_size, **mpnn_layer_kwargs)\n",
        "            for _ in range(mpnn_n_layers)\n",
        "        ])\n",
        "        self.readout = readout_cls(hidden_size=hidden_size)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            graph: a DGLGraph that contains the graph structure and node/edge features in a sparse format\n",
        "        Returns:\n",
        "            predictions: the final predictions\n",
        "        \"\"\"\n",
        "        node_embeddings, edge_embeddings = graph.ndata['h'], graph.edata['e']\n",
        "        node_embeddings = self.linear_node(node_embeddings)\n",
        "        edge_embeddings = self.linear_edge(\n",
        "            edge_embeddings)  # some of the models does not use edge features, but we won't use if-clauses for convenience.\n",
        "        for layer in self.mpnn_layers:\n",
        "            node_embeddings = layer(node_embeddings=node_embeddings, edge_embeddings=edge_embeddings, graph=graph)\n",
        "        graph_embedding = self.readout(node_embeddings, graph)\n",
        "        predictions = self.mlp(graph_embedding)\n",
        "        return predictions"
      ],
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "id": "b9ac59d947b4000b",
      "metadata": {
        "collapsed": false,
        "id": "b9ac59d947b4000b"
      },
      "source": [
        "## Readout\n",
        "Readout operation is used to aggregate node embeddings to obtain a graph embedding. There are many different readout operations, but the most popular are: sum, mean, attention, and max. We are going to implement the first three of them. Summing over nodes' embeddings seems trivial, but they're stored in a sparse format, meaning that all the nodes form all the graphs in a batch are stored in a one tensor of size `[num_nodes_1 + num_nodes_2 + ... + num_nodes_N, hidden_size]':   "
      ]
    },
    {
      "cell_type": "code",
      "id": "473300e58a6023b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "473300e58a6023b7",
        "outputId": "7c90a330-a896-40c5-ecb7-80b8b1f73e02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([23, 16]), tensor([13,  5,  5], dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "batched_graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "node_embeddings = linear(batched_graph.ndata['h'])\n",
        "node_embeddings.shape, batched_graph.batch_num_nodes()"
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "id": "fce302b7c444ae16",
      "metadata": {
        "collapsed": false,
        "id": "fce302b7c444ae16"
      },
      "source": [
        "For simplicity, we will convert the sparse node embeddings to a dense format with padding. Then the shape of the node embeddings will be `[batch_size, max_num_nodes, hidden_size]`. We can use the `to_dense_batch` function from `torch_geometric` for that:"
      ]
    },
    {
      "cell_type": "code",
      "id": "a3fd81a5384d2ad0",
      "metadata": {
        "id": "a3fd81a5384d2ad0"
      },
      "source": [
        "from typing import Tuple\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "\n",
        "def to_dense_embeddings(node_embeddings: torch.Tensor,\n",
        "                        graph: dgl.DGLGraph,\n",
        "                        fill_value: float = 0.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Converts sparse node embeddings to dense node embeddings with padding.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        graph: a batch of graphs\n",
        "        fill_value: a value to fill the padding with\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    \"\"\"\n",
        "    num_nodes = graph.batch_num_nodes() # e.g. [2, 3, 3]\n",
        "    indices = torch.arange(len(num_nodes), device=num_nodes.device)\n",
        "    batch = torch.repeat_interleave(indices, num_nodes).long() # e.g. [0, 0, 1, 1, 1, 2, 2, 2]\n",
        "    return to_dense_batch(node_embeddings, batch,\n",
        "                          fill_value=fill_value)  # that's the only reason we have torch_geometric in the requirements\n",
        "\n",
        "\n",
        "def to_sparse_embeddings(node_embeddings: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Converts dense node embeddings to sparse node embeddings.\n",
        "    Arguments:\n",
        "        node_embeddings: node embeddings in a dense format, i.e. [batch_size, max_num_nodes, hidden_size]\n",
        "        mask: a mask indicating which nodes are real and which are padding, i.e. [batch_size, max_num_nodes]\n",
        "    Returns:\n",
        "        node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "    \"\"\"\n",
        "    return node_embeddings[mask]"
      ],
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "id": "4190f0ff3fa0ae1f",
      "metadata": {
        "collapsed": false,
        "id": "4190f0ff3fa0ae1f"
      },
      "source": [
        "Now, we can simply convert the node embeddings to a dense format and sum them $x = \\sum_i^n x_i$:"
      ]
    },
    {
      "cell_type": "code",
      "id": "841a8932a12397f3",
      "metadata": {
        "id": "841a8932a12397f3"
      },
      "source": [
        "class SumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # We can also use dgl.sum_nodes function, but let assume it's forbidden in that notebook ;)\n",
        "        node_embeddings, _ = to_dense_embeddings(node_embeddings, graph)\n",
        "        return node_embeddings.sum(dim=1)"
      ],
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "id": "447a28b93e6e8e89",
      "metadata": {
        "id": "447a28b93e6e8e89"
      },
      "source": [
        "def test_readout(readout_cls: Type[ReadoutBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1], dataset[2][1]])\n",
        "    linear = nn.Linear(node_featurizer.feat_size(), 16)\n",
        "    node_embeddings = linear(graph.ndata['h'])\n",
        "    readout = readout_cls(hidden_size=16)\n",
        "    result = readout(node_embeddings, graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-3)"
      ],
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "id": "b5dd5e1b3bbde2cc",
      "metadata": {
        "id": "b5dd5e1b3bbde2cc"
      },
      "source": [
        "test_readout(SumReadout, expected_sum_readout)"
      ],
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "id": "579fd18386daaed",
      "metadata": {
        "collapsed": false,
        "id": "579fd18386daaed"
      },
      "source": [
        "### Task 1. Implement mean readout (1 point).\n",
        "Implement the mean readout given by formula $x = \\frac{1}{n}\\sum_i^n x_i$:"
      ]
    },
    {
      "cell_type": "code",
      "id": "13bd85d993f87d63",
      "metadata": {
        "id": "13bd85d993f87d63"
      },
      "source": [
        "class MeanReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # Using batch_num_nodes to determine the number of nodes in each graph\n",
        "        batch_sizes = graph.batch_num_nodes()\n",
        "        graph_ids = torch.repeat_interleave(torch.arange(len(batch_sizes), device=node_embeddings.device), batch_sizes)\n",
        "\n",
        "        # Compute mean embeddings for each graph using scatter_mean\n",
        "        batch_size = len(batch_sizes)\n",
        "        hidden_size = node_embeddings.size(1)\n",
        "        graph_embeddings = torch.zeros(batch_size, hidden_size, device=node_embeddings.device)\n",
        "        graph_counts = torch.zeros(batch_size, device=node_embeddings.device)\n",
        "\n",
        "        graph_embeddings.index_add_(0, graph_ids, node_embeddings)\n",
        "        graph_counts.index_add_(0, graph_ids, torch.ones_like(graph_ids, dtype=torch.float))\n",
        "\n",
        "        graph_embeddings /= graph_counts.unsqueeze(1)\n",
        "        return graph_embeddings\n",
        "\n",
        "test_readout(MeanReadout, expected_mean_readout)"
      ],
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "id": "db68abdbc2736d7a",
      "metadata": {
        "collapsed": false,
        "id": "db68abdbc2736d7a"
      },
      "source": [
        "### Task 2. Implement attention readout (2 points).\n",
        "Implement the attention readout given by formula $x = \\sum_i^n \\frac{\\exp(score_i))}{\\sum_j^n \\exp(score_j)}x_i$, where $score_i=score\\_mlp(x_i)$:"
      ]
    },
    {
      "cell_type": "code",
      "id": "6c1f5bcdbc90881",
      "metadata": {
        "id": "6c1f5bcdbc90881"
      },
      "source": [
        "class AttentionReadout(ReadoutBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__(hidden_size)\n",
        "        self.score_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        #Compute scores for each node\n",
        "        scores = self.score_mlp(node_embeddings).squeeze(-1)  # Shape: [total_num_nodes]\n",
        "\n",
        "        # Normalize scores using softmax within each graph\n",
        "        graph_ids = graph.batch_num_nodes()  # Number of nodes per graph in the batch\n",
        "        batch_ids = torch.repeat_interleave(torch.arange(len(graph_ids), device=node_embeddings.device), graph_ids)\n",
        "        exp_scores = torch.exp(scores)\n",
        "        norm_scores = exp_scores / torch.zeros_like(scores).index_add_(0, batch_ids, exp_scores).gather(0, batch_ids)\n",
        "\n",
        "        # Weighted sum of node embeddings\n",
        "        weighted_node_embeddings = node_embeddings * norm_scores.unsqueeze(-1)\n",
        "        graph_embeddings = torch.zeros(len(graph_ids), node_embeddings.size(1), device=node_embeddings.device)\n",
        "        graph_embeddings.index_add_(0, batch_ids, weighted_node_embeddings)\n",
        "\n",
        "        return graph_embeddings\n",
        "\n",
        "\n",
        "test_readout(AttentionReadout, expected_attention_readout)"
      ],
      "outputs": [],
      "execution_count": 40
    },
    {
      "cell_type": "markdown",
      "id": "ac465a3b9279474b",
      "metadata": {
        "collapsed": false,
        "id": "ac465a3b9279474b"
      },
      "source": [
        "## Message Passing Neural Networks (MPNNs)\n",
        "Message Passing is given by formula:\n",
        "$$\n",
        "x'_i=\\rho(x_i, \\square_{j\\in N(i)} \\psi(x_j, x_i, e_{ji})),\n",
        "$$\n",
        "where $\\psi$ is learnable message function, $\\rho$ is learnable update, and $\\square$ is aggregation function. $N(i)$ denotes the set of neighbors of node $i$. Note that in our dataset we added self-loops to every node, so $N(i)$ also contains $i$, but we don't bother with that."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "307c236e3cb84e76",
      "metadata": {
        "collapsed": false,
        "id": "307c236e3cb84e76"
      },
      "source": [
        "### Simple MPNN\n",
        "For instance, we can define a very simple MPNN layer by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j,\n",
        "$$\n",
        "where W_i are linear layers with implicit bias term (we will make the bias implicit in every formula in that notebook). Let us implement this simple MPNN:"
      ]
    },
    {
      "cell_type": "code",
      "id": "f11f284c299831ed",
      "metadata": {
        "id": "f11f284c299831ed"
      },
      "source": [
        "class SimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # graph is bi-directed, so we can freely swap the \"start\" and \"end\" meanings\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst') # using this `order` value sorts the `start_nodes`\n",
        "        messages = self.linear_3(node_embeddings[end_nodes]) # W_3x_j\n",
        "        message_dense, _ = to_dense_batch(messages, start_nodes.long(), fill_value=0.0) # to make the life easier, we convert the node embeddings to dense representation\n",
        "        aggregated_message = message_dense.sum(dim=1) # \\sum_{j\\in N(i)} W_3x_j\n",
        "        aggregated_message = self.linear_2(aggregated_message) # W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        node_embeddings = self.linear_1(node_embeddings) + aggregated_message # W_1x_i + W_2\\sum_{j\\in N(i)} W_3x_j\n",
        "        return node_embeddings"
      ],
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "id": "8767bffa62008f67",
      "metadata": {
        "id": "8767bffa62008f67"
      },
      "source": [
        "def test_mpnn_layer(mpnn_layer_cls: Type[MPNNLayerBase], expected_output: torch.Tensor):\n",
        "    torch.manual_seed(0)\n",
        "    graph = dgl.batch([dataset[0][1], dataset[1][1]])\n",
        "    linear_nodes = nn.Linear(node_featurizer.feat_size(), 4)\n",
        "    linear_edges = nn.Linear(edge_featurizer.feat_size(), 4)\n",
        "    node_embeddings = linear_nodes(graph.ndata['h'])\n",
        "    edge_embeddings = linear_edges(graph.edata['e'])\n",
        "    layer = mpnn_layer_cls(hidden_size=4)\n",
        "    result = layer(node_embeddings, edge_embeddings, graph)\n",
        "    assert torch.allclose(result, expected_output, atol=1e-3)"
      ],
      "outputs": [],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "id": "461980b684728501",
      "metadata": {
        "id": "461980b684728501"
      },
      "source": [
        "test_mpnn_layer(SimpleMPNNLayer, expected_simple_mpnn_output)"
      ],
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "markdown",
      "id": "d0dbbc2f2efa8ca2",
      "metadata": {
        "collapsed": false,
        "id": "d0dbbc2f2efa8ca2"
      },
      "source": [
        "### Task 3. Implement GraphSAGE layer (2 points).\n",
        "Implement a GraphSAGE given by the following formula:\n",
        "$$\n",
        "x'_i=W_1x_i + W_2\\frac{1}{deg(i)}\\sum_{j\\in N(i)} x_j,\n",
        "$$\n",
        "where $deg(i) = #N(i)$ is the number of neighbors of node $i$."
      ]
    },
    {
      "cell_type": "code",
      "id": "82528a8dacf24cd3",
      "metadata": {
        "id": "82528a8dacf24cd3"
      },
      "source": [
        "class SAGELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "         # Получаем индексы вершин начала и конца для каждого ребра\n",
        "        # (для неориентированного графа в DGL хранятся 2 направления).\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst')\n",
        "\n",
        "        # Создаем «аккумулятор» для суммы соседей\n",
        "        # Его размер: [число_вершин, hidden_size]\n",
        "        # В начале он заполнен нулями\n",
        "        aggregated = torch.zeros_like(node_embeddings)\n",
        "\n",
        "        # Добавляем (суммируем) эмбеддинги end_nodes в соответствующие позиции start_nodes\n",
        "        # Таким образом для каждой вершины i в aggregated[i] накопится сумма x_j по всем j in N(i)\n",
        "        aggregated.index_add_(0, start_nodes, node_embeddings[end_nodes])\n",
        "\n",
        "        # Делим на степень (число соседей).\n",
        "        # Для ориентированного графа используем out_degrees (но для неориентированного разницы не будет).\n",
        "        deg = graph.out_degrees().clamp(min=1).unsqueeze(-1)  # [num_nodes, 1]\n",
        "        aggregated = aggregated / deg\n",
        "\n",
        "        # Применяем линейный слой W_2 к усреднённой сумме соседей\n",
        "        aggregated = self.linear_2(aggregated)\n",
        "\n",
        "        # Применяем W_1 к исходным эмбеддингам + добавляем агрегированные эмбеддинги\n",
        "        node_embeddings = self.linear_1(node_embeddings) + aggregated\n",
        "\n",
        "        return node_embeddings\n",
        "\n",
        "test_mpnn_layer(SAGELayer, expected_sage_layer_output)"
      ],
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "id": "ea8735b272ecad46",
      "metadata": {
        "collapsed": false,
        "id": "ea8735b272ecad46"
      },
      "source": [
        "### Task 4. Implement GIN layer (2 points).\n",
        "Implement a GIN layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} x_j).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "id": "e422bea1856fc29",
      "metadata": {
        "id": "e422bea1856fc29"
      },
      "source": [
        "class GINLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = eps\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # В DGL для неориентированного графа хранятся 2 направления ребра,\n",
        "        # поэтому start_nodes и end_nodes вместе покрывают все пары (i, j) и (j, i).\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst')\n",
        "\n",
        "        # Инициализируем аккумулятор для суммы соседей: [num_nodes, hidden_size]\n",
        "        aggregated = torch.zeros_like(node_embeddings)\n",
        "\n",
        "        # Для каждой вершины i суммируем эмбеддинги соседей j -> aggregated[i] += node_embeddings[j]\n",
        "        aggregated.index_add_(0, start_nodes, node_embeddings[end_nodes])\n",
        "\n",
        "        # Прибавляем (1 + eps)* x_i\n",
        "        aggregated = aggregated + (1.0 + self.eps) * node_embeddings\n",
        "\n",
        "        # Пропускаем через MLP\n",
        "        updated = self.mlp(aggregated)\n",
        "\n",
        "        return updated\n",
        "\n",
        "test_mpnn_layer(GINLayer, expected_gin_layer_output)"
      ],
      "outputs": [],
      "execution_count": 45
    },
    {
      "cell_type": "markdown",
      "id": "9fe4ec2134b539da",
      "metadata": {
        "collapsed": false,
        "id": "9fe4ec2134b539da"
      },
      "source": [
        "### Task 5. Implement GINE layer (2 points).\n",
        "Implement a GINE layer given by the following formula:\n",
        "$$\n",
        "x'_i=mlp((1 + \\epsilon)x_i + \\sum_{j\\in N(i)} ReLU(x_j + e_{ji})).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "id": "635e6bcb4e40fdd2",
      "metadata": {
        "id": "635e6bcb4e40fdd2"
      },
      "source": [
        "class GINELayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int, eps: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.eps = eps\n",
        "        self.relu = nn.ReLU()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        # Для неориентированного графа хранится два направления,\n",
        "        # поэтому у каждой связи есть start_nodes и end_nodes для обоих направлений.\n",
        "        # edge_ids обеспечивает соответствие ребру (для edge_embeddings).\n",
        "        start_nodes, end_nodes, edge_ids = graph.edges(order='srcdst', form='all')\n",
        "\n",
        "        # Инициализируем «аккумулятор» для суммы ReLU(x_j + e_{ji}) по соседям\n",
        "        aggregated = torch.zeros_like(node_embeddings)\n",
        "\n",
        "        # Для каждого ребра добавляем сообщение:\n",
        "        # ReLU(node_embeddings[end_nodes] + edge_embeddings[edge_ids])\n",
        "        # в соответствующую вершину start_nodes\n",
        "        msg = self.relu(node_embeddings[end_nodes] + edge_embeddings[edge_ids])\n",
        "        aggregated.index_add_(0, start_nodes, msg)\n",
        "\n",
        "        # Добавляем (1 + eps) * x_i\n",
        "        aggregated = aggregated + (1.0 + self.eps) * node_embeddings\n",
        "\n",
        "        # Пропускаем через MLP\n",
        "        updated = self.mlp(aggregated)\n",
        "        return updated\n",
        "\n",
        "test_mpnn_layer(GINELayer, expected_gine_layer_output)"
      ],
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "markdown",
      "id": "6b220afd7f1d78b8",
      "metadata": {
        "collapsed": false,
        "id": "6b220afd7f1d78b8"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f465e5d378487e7",
      "metadata": {
        "collapsed": false,
        "id": "2f465e5d378487e7"
      },
      "source": [
        "## Logger\n",
        "We are going to use [wandb](https://wandb.ai/site) for logging. It's a very convenient tool for logging and visualizing the training process. It's free for academic use, so you can create an account and use it for your projects. If you don't want to use wandb, you can use any other online logger (like [comet.ml](https://www.comet.ml/site/)), but you need to implement the appropriate LoggerBase subclass on your own. To setup and use wandb, you need to do the following:\n",
        "1. [Setup the wandb](https://docs.wandb.ai/quickstart) (or any other online logger).\n",
        "2. Give your supervisor access to your project (ask him/her about the username.\n",
        "3. Use the logger for all your trainings and provide the links to the final runs."
      ]
    },
    {
      "cell_type": "code",
      "id": "1462ef331426d529",
      "metadata": {
        "id": "1462ef331426d529"
      },
      "source": [
        "class WandbLogger(LoggerBase):\n",
        "    def __init__(\n",
        "            self, logdir: str | Path, project_name: str, experiment_name: str, **kwargs: Dict[str, Any]\n",
        "    ):\n",
        "        super().__init__(logdir)\n",
        "        import wandb\n",
        "        self.project_name = project_name\n",
        "        self.experiment_name = experiment_name\n",
        "        self.kwargs = kwargs\n",
        "        self.run = wandb.init(\n",
        "            dir=self.logdir,\n",
        "            project=self.project_name,\n",
        "            name=self.experiment_name,\n",
        "            **self.kwargs,\n",
        "        )\n",
        "\n",
        "    def log_metrics(self, metrics: Dict[str, Any], prefix: str):\n",
        "        metrics = {f\"{prefix}/{k}\": v for k, v in metrics.items()}\n",
        "        self.run.log(metrics)\n",
        "\n",
        "    def close(self):\n",
        "        self.run.finish()"
      ],
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "id": "1db91eaab1a90175",
      "metadata": {
        "collapsed": false,
        "id": "1db91eaab1a90175"
      },
      "source": [
        "## Task 6. Train GraphSAGE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `SAGELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0?nw=nwuserchavgun97\n"
      ]
    },
    {
      "cell_type": "code",
      "id": "e3e9e0cf69701d46",
      "metadata": {
        "id": "e3e9e0cf69701d46"
      },
      "source": [
        "### Example code for training. You can modify it for easier grid-searching."
      ],
      "outputs": [],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "id": "2980b66ad10a9824",
      "metadata": {
        "id": "2980b66ad10a9824"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def get_time_stamp() -> str:\n",
        "    return datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
      ],
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "id": "18cd039ad8f03ca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2876f6060bea44b7abe9ad7e71c5c2b2",
            "9dd5e45f57f84da5b5ac82cb7b2cef30",
            "c86e74657a484b1f85c398b310f3ee98",
            "495978d97d2e4e4d8dc148e72e2a0b7b",
            "c61b3810922945e88788bbd1a0d5389e",
            "6be50c32ab8a4bc095cfdc0f63b04242",
            "8409f8316fc94b5c875020fe581b2a21",
            "92c560d775884fffa1fb7d1fc875b822",
            "6875da845eee4f2aac0cfd277a3812a7",
            "afbbaf303bc840128ac35119ad802762",
            "0ba21ea8372547de8a5858210606bd62"
          ]
        },
        "id": "18cd039ad8f03ca6",
        "outputId": "52db7ae7-f87b-4dc4-8806-2aa678baaf29"
      },
      "source": [
        "from torchmetrics import MeanAbsoluteError as MAE\n",
        "from torchmetrics import MeanSquaredError as MSE\n",
        "from torchmetrics import PearsonCorrCoef as PCC\n",
        "\n",
        "metrics = {\n",
        "    \"mae\": MAE(),\n",
        "    \"mse\": MSE(),\n",
        "    \"pcc\": PCC(),\n",
        "}\n",
        "\n",
        "model = GNN(\n",
        "    node_features_size=node_featurizer.feat_size(),\n",
        "    edge_features_size=edge_featurizer.feat_size(),\n",
        "    hidden_size=256,\n",
        "    output_size=1,\n",
        "    mpnn_layer_cls=SAGELayer,\n",
        "    mpnn_n_layers=6,\n",
        "    readout_cls=MeanReadout,\n",
        "    mpnn_layer_kwargs={}\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    run_dir=\"experiments\",\n",
        "    train_dataset=train,\n",
        "    valid_dataset=valid,\n",
        "    train_metrics=metrics,\n",
        "    valid_metrics=metrics,\n",
        "    train_batch_size=32,\n",
        "    model=model,\n",
        "    logger=WandbLogger(\n",
        "        logdir=\"runs/mpnn\",\n",
        "        project_name=\"mldd23\",\n",
        "        experiment_name=f\"sage_{get_time_stamp()}\",\n",
        "    ),\n",
        "    optimizer_kwargs={\"lr\": 1e-4},\n",
        "    n_epochs=50,\n",
        "    device=\"cpu\",\n",
        "    valid_every_n_epochs=1,\n",
        ")\n",
        "\n",
        "valid_metrics = trainer.train()\n",
        "test_metrics = trainer.test(test)\n",
        "trainer.close()\n",
        "print(f\"Validation metrics: {valid_metrics}\")\n",
        "print(f\"Test metrics: {test_metrics}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>runs/mpnn/wandb/run-20250111_182642-6fxpc7o0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0' target=\"_blank\">sage_2025-01-11_18-17-58</a></strong> to <a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23' target=\"_blank\">https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0' target=\"_blank\">https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2876f6060bea44b7abe9ad7e71c5c2b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: The variance of predictions or target is close to zero. This can cause instability in Pearson correlationcoefficient, leading to wrong results. Consider re-scaling the input if possible or computing using alarger dtype (currently using torch.float32).\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/mae</td><td>▁</td></tr><tr><td>test/mse</td><td>▁</td></tr><tr><td>test/pcc</td><td>▁</td></tr><tr><td>train/loss</td><td>▇▄▁▅▄▇▅▃▄▄▅▅▄▃▃▅▂▂▂▂▄▁▃▄▂▂▄▂▂▃▃▂▂▃▃█▅▂▃▄</td></tr><tr><td>train/mae</td><td>▇▆▇▆▆▆█▆▆▅▇▆▆▇▅▄▅▆▆▄▄▄▅▅▅▄▃▄▅▅▁▄▄▃▄▄▅▄▄▄</td></tr><tr><td>train/mse</td><td>▄▄▅█▄▁▄▄▄▄▄▃▄▄▄▂▁▂▃▅▂▂▂▃▂▂▁▂▂▃▂▂▂▃▂▂▂▂▄▂</td></tr><tr><td>train/pcc</td><td>▃▁▄▄▅▆▆█▆▃▅▃ ▇▇▇▇▇▆▆▇▇█▆▇▇▇█▇██▇▇▆▇▇█▇██</td></tr><tr><td>valid/loss</td><td>▆██▆▅▆▆▆▅▅▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁</td></tr><tr><td>valid/mae</td><td>█▄▄▄▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>valid/mse</td><td>█▄▅▄▄▄▃▃▂▃▃▂▂▂▂▃▃▃▂▂▂▂▂▂▄▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>valid/pcc</td><td>▁▃▄▄▄▆███████████▇██▇▇▇▇▇▇██▇▇█▇▇█▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test/loss</td><td>8.16485</td></tr><tr><td>test/mae</td><td>2.17855</td></tr><tr><td>test/mse</td><td>7.37442</td></tr><tr><td>test/pcc</td><td>0.7087</td></tr><tr><td>train/loss</td><td>2.55186</td></tr><tr><td>train/mae</td><td>1.59745</td></tr><tr><td>train/mse</td><td>2.55186</td></tr><tr><td>train/pcc</td><td>nan</td></tr><tr><td>valid/loss</td><td>15.65676</td></tr><tr><td>valid/mae</td><td>3.31475</td></tr><tr><td>valid/mse</td><td>15.65676</td></tr><tr><td>valid/pcc</td><td>0.8755</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sage_2025-01-11_18-17-58</strong> at: <a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0' target=\"_blank\">https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23/runs/6fxpc7o0</a><br> View project at: <a href='https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23' target=\"_blank\">https://wandb.ai/chavgun97-uniwersytet-jagiello-ski-w-krakowie/mldd23</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>runs/mpnn/wandb/run-20250111_182642-6fxpc7o0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'loss': 15.656756162643433, 'mae': 3.3147473335266113, 'mse': 15.656755447387695, 'pcc': 0.8755006790161133}\n",
            "Test metrics: {'loss': 8.16485300064087, 'mae': 2.1785459518432617, 'mse': 7.374423503875732, 'pcc': 0.7087031602859497}\n"
          ]
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "markdown",
      "id": "c0acbbdb6f55d814",
      "metadata": {
        "collapsed": false,
        "id": "c0acbbdb6f55d814"
      },
      "source": [
        "## Task 7. Train GIN (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINLayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jCtjGUg9qT83"
      },
      "id": "jCtjGUg9qT83",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "100ee2cd44877b2c",
      "metadata": {
        "collapsed": false,
        "id": "100ee2cd44877b2c"
      },
      "source": [
        "## Task 8. Train GINE (2 points).\n",
        "1. Tune hyperparameters of a GNN with `GINELayer` as MPNN layer to obtain at most 2.0 MAE on the validation set. You can modify the GNN/MPNN architecture, so it uses some regularization tricks like dropout or batch norm. Don't change the validation batch size. If your validation MAE is in (2.0, 2.5], you can obtain 1 point.\n",
        "2. Report the obtained MAE on the validation and test set (only the former need to be lower than 2.0 MAE).\n",
        "3. Provide the link to the final run: [your link]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802615e3afaddf44",
      "metadata": {
        "collapsed": false,
        "id": "802615e3afaddf44"
      },
      "source": [
        "# Code optimization\n",
        "Some pieces of code were written suboptimally. Your task is to slightly optimize them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17c64785b23a2b1d",
      "metadata": {
        "collapsed": false,
        "id": "17c64785b23a2b1d"
      },
      "source": [
        "## Task 9. Optimize SumReadout (1 point).\n",
        "`SumReadout` was written using `to_dense_embeddings` function which does some unecessary memory allocations and computations. Your task is to rewrite the method using code from a bare torch library. Hint: `torch.index_add`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "292cb0197e977862",
      "metadata": {
        "is_executing": true,
        "id": "292cb0197e977862"
      },
      "source": [
        "class OptimizedSumReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        # Получаем число вершин для каждого графа в батче\n",
        "        batch_sizes = graph.batch_num_nodes()  # Пример: [2, 3, 3]\n",
        "        batch_size = len(batch_sizes)\n",
        "\n",
        "        # Для каждой вершины указываем, к какому графу она принадлежит:\n",
        "        # Например, [0, 0, 1, 1, 1, 2, 2, 2]\n",
        "        batch_index = torch.repeat_interleave(\n",
        "            torch.arange(batch_size, device=node_embeddings.device),\n",
        "            batch_sizes\n",
        "        )\n",
        "\n",
        "        # Создаём аккумулятор для сумм\n",
        "        graph_embeddings = torch.zeros(batch_size, node_embeddings.size(1), device=node_embeddings.device)\n",
        "\n",
        "        # Суммируем в graph_embeddings[node's batch_id] += node_embeddings\n",
        "        graph_embeddings.index_add_(0, batch_index, node_embeddings)\n",
        "\n",
        "        return graph_embeddings\n",
        "\n",
        "test_readout(OptimizedSumReadout, expected_sum_readout)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d4be6a2ed6011b64",
      "metadata": {
        "collapsed": false,
        "id": "d4be6a2ed6011b64"
      },
      "source": [
        "## Task 10. Optimize MeanReadout (1 point).\n",
        "Your task is to rewrite the method using code from a bare torch library."
      ]
    },
    {
      "cell_type": "code",
      "id": "9baf5944d7ad42c2",
      "metadata": {
        "is_executing": true,
        "id": "9baf5944d7ad42c2"
      },
      "source": [
        "class OptimizedMeanReadout(ReadoutBase):\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Attributes:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            graph_embeddings: graph embeddings of shape.[batch_size, hidden_size]\n",
        "        \"\"\"\n",
        "        batch_sizes = graph.batch_num_nodes()       # Пример: [2, 3, 3]\n",
        "        batch_size = len(batch_sizes)\n",
        "\n",
        "        # batch_index[i]-у соответствуют вершины i-го графа\n",
        "        batch_index = torch.repeat_interleave(\n",
        "            torch.arange(batch_size, device=node_embeddings.device),\n",
        "            batch_sizes\n",
        "        )\n",
        "\n",
        "        # Создаём аккумулятор\n",
        "        graph_embeddings = torch.zeros(batch_size, node_embeddings.size(1), device=node_embeddings.device)\n",
        "\n",
        "        # Складываем все node_embeddings\n",
        "        graph_embeddings.index_add_(0, batch_index, node_embeddings)\n",
        "\n",
        "        # Делим каждую строку на число вершин в соответствующем графе\n",
        "        # batch_sizes: [batch_size] -> делаем [batch_size, 1] для броадкаста\n",
        "        graph_embeddings /= batch_sizes.unsqueeze(1).float()\n",
        "\n",
        "        return graph_embeddings\n",
        "\n",
        "\n",
        "test_readout(OptimizedMeanReadout, expected_mean_readout)"
      ],
      "outputs": [],
      "execution_count": 53
    },
    {
      "cell_type": "markdown",
      "id": "6b0f8cab6725a285",
      "metadata": {
        "collapsed": false,
        "id": "6b0f8cab6725a285"
      },
      "source": [
        "## Task 11. Optimize SimpleMPNNLayer (1 point).\n",
        "We can make our implementations of `SimpleMPNNLayer` layer (and basically any other MPNN layer) slightly faster by:\n",
        "- reducing the costs of the message embedding (in the case of `SimpleMPNNLayer`, it's application of `self.linear_3`) from $O(m)$ to $O(n)$, where $m$ is the number of edges in the graph and $n$ is the number of nodes.\n",
        "- removing quite expensive `to_dense_batch` call.\n",
        "\n",
        "Your task is to apply the above optimizations."
      ]
    },
    {
      "cell_type": "code",
      "id": "862db51e45f8abf",
      "metadata": {
        "is_executing": true,
        "id": "862db51e45f8abf"
      },
      "source": [
        "class OptimizedSimpleMPNNLayer(MPNNLayerBase):\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.linear_1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self,\n",
        "                node_embeddings: torch.Tensor,\n",
        "                edge_embeddings: torch.Tensor,\n",
        "                graph: dgl.DGLGraph) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            node_embeddings: node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "            edge_embeddings: edge embeddings in a sparse format, i.e. [total_num_edges, hidden_size]\n",
        "            graph: a DGLGraph that contains the graph structure\n",
        "        Returns:\n",
        "            node_embeddings: updated node embeddings in a sparse format, i.e. [total_num_nodes, hidden_size]\n",
        "        \"\"\"\n",
        "        start_nodes, end_nodes = graph.edges(order='srcdst')\n",
        "\n",
        "        # (1) Применяем W3 к каждому узлу один раз\n",
        "        tmp = self.linear_3(node_embeddings)  # [num_nodes, hidden_size]\n",
        "\n",
        "        # (2) Аккумулируем сумму соседских эмбеддингов\n",
        "        aggregated = torch.zeros_like(tmp)  # [num_nodes, hidden_size]\n",
        "        aggregated.index_add_(0, start_nodes, tmp[end_nodes])\n",
        "\n",
        "        # (3) Применяем W2 к накопленной сумме\n",
        "        aggregated = self.linear_2(aggregated)\n",
        "\n",
        "        # (4) Складываем W1 x_i + W2(...)\n",
        "        out = self.linear_1(node_embeddings) + aggregated\n",
        "\n",
        "        return out\n",
        "\n",
        "test_mpnn_layer(OptimizedSimpleMPNNLayer, expected_simple_mpnn_output)"
      ],
      "outputs": [],
      "execution_count": 54
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b284230058d74e42a500416500d08ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fae3655b19d405f83b190de344b92d3",
              "IPY_MODEL_a0439ca35e774705a20af1ecfe258c3b",
              "IPY_MODEL_07f88eff19324c67aa25f67c7082a94b"
            ],
            "layout": "IPY_MODEL_5e00f9a70be44a08933b3988a180e302"
          }
        },
        "9fae3655b19d405f83b190de344b92d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1491a96d59804c10b66f314abf355061",
            "placeholder": "​",
            "style": "IPY_MODEL_f73966e6f43b45dfbe922ea2079e4e88",
            "value": "/root/.dgl/FreeSolv.zip: 100%"
          }
        },
        "a0439ca35e774705a20af1ecfe258c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041912511f044599b363309886a1d237",
            "max": 11306,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd1ec0c3949b46ebae2dab78530b9dee",
            "value": 11306
          }
        },
        "07f88eff19324c67aa25f67c7082a94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9502bcf5090d482da8417c0d0b574c7b",
            "placeholder": "​",
            "style": "IPY_MODEL_afe6245eeee94220a59e13396ad1bac8",
            "value": " 11.3k/11.3k [00:00&lt;00:00, 649kB/s]"
          }
        },
        "5e00f9a70be44a08933b3988a180e302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1491a96d59804c10b66f314abf355061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f73966e6f43b45dfbe922ea2079e4e88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041912511f044599b363309886a1d237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1ec0c3949b46ebae2dab78530b9dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9502bcf5090d482da8417c0d0b574c7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe6245eeee94220a59e13396ad1bac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2876f6060bea44b7abe9ad7e71c5c2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dd5e45f57f84da5b5ac82cb7b2cef30",
              "IPY_MODEL_c86e74657a484b1f85c398b310f3ee98",
              "IPY_MODEL_495978d97d2e4e4d8dc148e72e2a0b7b"
            ],
            "layout": "IPY_MODEL_c61b3810922945e88788bbd1a0d5389e"
          }
        },
        "9dd5e45f57f84da5b5ac82cb7b2cef30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6be50c32ab8a4bc095cfdc0f63b04242",
            "placeholder": "​",
            "style": "IPY_MODEL_8409f8316fc94b5c875020fe581b2a21",
            "value": "100%"
          }
        },
        "c86e74657a484b1f85c398b310f3ee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c560d775884fffa1fb7d1fc875b822",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6875da845eee4f2aac0cfd277a3812a7",
            "value": 50
          }
        },
        "495978d97d2e4e4d8dc148e72e2a0b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afbbaf303bc840128ac35119ad802762",
            "placeholder": "​",
            "style": "IPY_MODEL_0ba21ea8372547de8a5858210606bd62",
            "value": " 50/50 [01:16&lt;00:00,  1.62s/it]"
          }
        },
        "c61b3810922945e88788bbd1a0d5389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be50c32ab8a4bc095cfdc0f63b04242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8409f8316fc94b5c875020fe581b2a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c560d775884fffa1fb7d1fc875b822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6875da845eee4f2aac0cfd277a3812a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afbbaf303bc840128ac35119ad802762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba21ea8372547de8a5858210606bd62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}